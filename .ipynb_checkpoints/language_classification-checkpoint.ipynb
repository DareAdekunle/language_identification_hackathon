{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Language Classsification\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    ">To \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "#libraries for...\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('resources/train_set.csv')\n",
    "test_df= pd.read_csv('resources/test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c777d5b",
   "metadata": {},
   "source": [
    "#### Visual Aseessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80201cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>afr</td>\n",
       "      <td>die nasionale polisiëringsbeleid kan voorsieni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8553</th>\n",
       "      <td>eng</td>\n",
       "      <td>the gariep dam more than km long and km wide i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25409</th>\n",
       "      <td>zul</td>\n",
       "      <td>kuyavunyelwana phakathi kwamaqembu ukuthi owen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8822</th>\n",
       "      <td>ssw</td>\n",
       "      <td>bofakazi labetako betawutsamela letinchubo ilo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>sot</td>\n",
       "      <td>mabapi le mebu e mengata e tla etswa diteko ts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>ssw</td>\n",
       "      <td>ngaphasi kwemibandzela yetimiso temtsetfosimis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>nbl</td>\n",
       "      <td>letha iforomo lesibawo elizalisiweko bi- negad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11301</th>\n",
       "      <td>afr</td>\n",
       "      <td>n party is geregtig op die toekenning aan hom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>afr</td>\n",
       "      <td>twee lede wat burgers van die provinsie is en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32794</th>\n",
       "      <td>tsn</td>\n",
       "      <td>fa o kgweetsa serori se se botlhofo mo tseleng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>tsn</td>\n",
       "      <td>lefelo le ne la kgakolwa la batho ba ba tshela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31202</th>\n",
       "      <td>tso</td>\n",
       "      <td>xivilelo xa klasi ii i xivilelo xa ku va mapho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10242</th>\n",
       "      <td>xho</td>\n",
       "      <td>izenzo zomsebenzi wokufama ezingalunganga kwim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>nbl</td>\n",
       "      <td>umsebenzi wombuso nakazakukghona ukusebenzela ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>ssw</td>\n",
       "      <td>njengobe sibungata kukhululwa kwamadiba lamuhl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19259</th>\n",
       "      <td>nso</td>\n",
       "      <td>hlohleletša tšweletšo le tšhomišo ya ditlabelo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>xho</td>\n",
       "      <td>b kwisehlo sokufa okwenzeka umntu ehanjiswa ok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15952</th>\n",
       "      <td>tsn</td>\n",
       "      <td>ngwana yo a umakiwang mo karolong ya molawana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>sot</td>\n",
       "      <td>molao wa naha wa metsi o dumella mmuso ho aha ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17296</th>\n",
       "      <td>ssw</td>\n",
       "      <td>uma ufaka sicelo sekutfola ipasipoti lephutfum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "5866      afr  die nasionale polisiëringsbeleid kan voorsieni...\n",
       "8553      eng  the gariep dam more than km long and km wide i...\n",
       "25409     zul  kuyavunyelwana phakathi kwamaqembu ukuthi owen...\n",
       "8822      ssw  bofakazi labetako betawutsamela letinchubo ilo...\n",
       "5992      sot  mabapi le mebu e mengata e tla etswa diteko ts...\n",
       "452       ssw  ngaphasi kwemibandzela yetimiso temtsetfosimis...\n",
       "1331      nbl  letha iforomo lesibawo elizalisiweko bi- negad...\n",
       "11301     afr  n party is geregtig op die toekenning aan hom ...\n",
       "1555      afr  twee lede wat burgers van die provinsie is en ...\n",
       "32794     tsn  fa o kgweetsa serori se se botlhofo mo tseleng...\n",
       "23813     tsn  lefelo le ne la kgakolwa la batho ba ba tshela...\n",
       "31202     tso  xivilelo xa klasi ii i xivilelo xa ku va mapho...\n",
       "10242     xho  izenzo zomsebenzi wokufama ezingalunganga kwim...\n",
       "8916      nbl  umsebenzi wombuso nakazakukghona ukusebenzela ...\n",
       "936       ssw  njengobe sibungata kukhululwa kwamadiba lamuhl...\n",
       "19259     nso  hlohleletša tšweletšo le tšhomišo ya ditlabelo...\n",
       "14978     xho  b kwisehlo sokufa okwenzeka umntu ehanjiswa ok...\n",
       "15952     tsn  ngwana yo a umakiwang mo karolong ya molawana ...\n",
       "7063      sot  molao wa naha wa metsi o dumella mmuso ho aha ...\n",
       "17296     ssw  uma ufaka sicelo sekutfola ipasipoti lephutfum..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get a visaual assessment of different sampled observations in the train dataset\n",
    "train_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>4699</td>\n",
       "      <td>LITAMBWA MBUDZISO 3 Zwo itwa - A. M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>812</td>\n",
       "      <td>Ke feela kalafi yeo e lego lenaneong la kalafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>Naa kalafi ya mmušeletšwa ke eng?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>4524</td>\n",
       "      <td>u thoma nḓila ya u shumana na tshililo tshiṅwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1785</td>\n",
       "      <td>laha xivangelo xa xiendlo xi humelelaka hi ku ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>1286</td>\n",
       "      <td>ya nako e dirang ka yona.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>2387</td>\n",
       "      <td>nyito ya u thivhela vhafumakadzi u wana ndaka ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>4212</td>\n",
       "      <td>Bekufana ligama nesibongo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>4461</td>\n",
       "      <td>Mo GEMS re ikgantšha ka phišegelo ya rena ya g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>4045</td>\n",
       "      <td>thusa vhavhilaeli kha u vhiga thoma matshimbid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>2242</td>\n",
       "      <td>Vhabebi vha khou gwalaba. A vha khou fushea ng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>233</td>\n",
       "      <td>a Pulani dza ndinganyiso , kha miṅwaha mivhili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>1797</td>\n",
       "      <td>maikarabelo a sepodisi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>406</td>\n",
       "      <td>Mofani ka ditirelo yo a kgethilwego (DSP): DSP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>5324</td>\n",
       "      <td>Klaargemaakte produkte geproduseer deur hierdi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>4243</td>\n",
       "      <td>Maemong a mang, ho pepa ka thipa ho ka hlokeha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>5266</td>\n",
       "      <td>ke lekgotlapeomolao ga o ka fa Molaotheong.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>1511</td>\n",
       "      <td>ndaela ya u ita uri zwikhala na pfanelo zwe vh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>5326</td>\n",
       "      <td>thanolo, tshireletso kgotsa tiragatso ya Molao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>1083</td>\n",
       "      <td>Umthetho wesizwe ungayilawula le nkqubo imisel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text\n",
       "4698   4699               LITAMBWA MBUDZISO 3 Zwo itwa - A. M.\n",
       "811     812  Ke feela kalafi yeo e lego lenaneong la kalafi...\n",
       "297     298                  Naa kalafi ya mmušeletšwa ke eng?\n",
       "4523   4524  u thoma nḓila ya u shumana na tshililo tshiṅwe...\n",
       "1784   1785  laha xivangelo xa xiendlo xi humelelaka hi ku ...\n",
       "1285   1286                          ya nako e dirang ka yona.\n",
       "2386   2387  nyito ya u thivhela vhafumakadzi u wana ndaka ...\n",
       "4211   4212                         Bekufana ligama nesibongo.\n",
       "4460   4461  Mo GEMS re ikgantšha ka phišegelo ya rena ya g...\n",
       "4044   4045  thusa vhavhilaeli kha u vhiga thoma matshimbid...\n",
       "2241   2242  Vhabebi vha khou gwalaba. A vha khou fushea ng...\n",
       "232     233  a Pulani dza ndinganyiso , kha miṅwaha mivhili...\n",
       "1796   1797                            maikarabelo a sepodisi.\n",
       "405     406  Mofani ka ditirelo yo a kgethilwego (DSP): DSP...\n",
       "5323   5324  Klaargemaakte produkte geproduseer deur hierdi...\n",
       "4242   4243    Maemong a mang, ho pepa ka thipa ho ka hlokeha.\n",
       "5265   5266        ke lekgotlapeomolao ga o ka fa Molaotheong.\n",
       "1510   1511  ndaela ya u ita uri zwikhala na pfanelo zwe vh...\n",
       "5325   5326  thanolo, tshireletso kgotsa tiragatso ya Molao...\n",
       "1082   1083  Umthetho wesizwe ungayilawula le nkqubo imisel..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get a visaual assessment of different sampled observations in the test dataset\n",
    "test_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c913e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isiketjhi somleyo wesikala saka sazo zoke izinto ezizakusetjenziswa etjhedeni lokusengela elibalwe ku-regulation lokhu kubala hlangana nokhunye iplani yehlabathini ukuqalwa kweplani bunqopha lapho izaba khona kanye nokuqalwa kweplani ujame ngaphezulu \n",
      "\n",
      "ngaphambi kokuthi umkhandlu esikhulu sesifundazwe siqale imisebenzi yezikhundla zaso kufanele amalungu afunge noma aqinisekise ukuthi azokwethembeka kwiriphabhuliki futhi athobele umthethosisekelo ngokuhambisana nesheduli \n",
      "\n",
      "inkqubo elandelwayo ngokuphathelele ekunikweni nasekwaliweni kwesicelo solwazi iqulethwe kumgaqo-nkqubo we-opsc kumthetho wokuphakanyiswa kufikelelo lolwazi umgaqo-nkqubo ufumaneka kwiwebhusayithi ye-psc ku-www psc gov \n",
      "\n",
      "i xiphemu xihi na xihi xa xitiviso lexi mumangari a nga xi twisiseki na ii switshunxo swa yena ku ya hi nawu na mfanelo wo endla xivilelo no e tivisa mumangari leswaku a kuma mahungu manwana kusuka eka matsalana wa khoto ya majisitarata loko swivutiso swa yena swi nga hlamuriwa \n",
      "\n",
      "kunekwemukelwa lokuniketwako kucalangaye wesihlanu kulokutsi nanobe tindzaba temphumelelo tivamisile kwenteka nakube kwekwehluleka ekuhleleni emamedali akakavamisi kuta ngengoti kutilungiselela kubaluleke kakhulu \n",
      "\n",
      "moarabi o tshwanetse ho hlahisa bopaki dintlheng tse ka pela lekgotla hore kgethollo ha ya ba teng jwalo ka ha ho na le menyenyetsi kapa moarabi o tshwanetse ho hlahisa bopaki ba hore boitshwaro ha bo a thehwa hodima le leng kapa a mang a mabaka thibetsweng \n",
      "\n",
      "eminyakeni lesitfupha leyengcile baholi bebantfu bakitsi bahlangana engungcutseleni yentfutfuko bafinyelela esivumelwaneni semisebenti sonkhe lokumele siyente kute sente ncono lizinga lemphilo yebahlali baseningizimu afrika ikakhulukati kwehlisa lizinga lekungasebenti nebuphuya ngahhafu nga- \n",
      "\n",
      "sibawa abafakazeli ababili esingakghona ukubathola umrholi womphakathi kunye nesikghwari esiwufundeleko umsebenzi wobukghwari abanqopheneko nomsebenzakho sibawa usithumelele ubufakazelo obutlolwe babe batlikitlelwa obubuya kubafakazeli ngenzasapha \n",
      "\n",
      "dikoporasi ke mekgatlo ye ikemetšego ka noši ya boithuši yeo e laolwago ke maloko a tšona di ka dira dikwano le mmušo le mekgatlo ye mengwe fela ba swanetše go kgonthiša gore ba dula ka fase ga taolo ya temokrasi ka mehla ya moloko a yona ga ba a swanela go laolwa ke mekgatlo ya ka ntle \n",
      "\n",
      "a ku na nkarhi wa ku rindza ku vika munhu loyi a nga nyamalala loko mutirhela-mfumo wo phorisa a ku byela swin wana swo hambana na leswi u fanele ku sindzisa ku vonana na muofisara wa xiyimo xa le henhla na swona u sindzisa mhaka leyi ku kota u kuma ku pfuniwa loku faneleke \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Futher look at the some smapled contents of contents of the text each dataset\n",
    "# Train Data\n",
    "for i in train_df['text'].sample(10):\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "758af7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_processing(text):\n",
    "    \"\"\"\n",
    "    Returns a sringof words, tokeninses and removes noise in the string\n",
    "    \n",
    "    Parameters:\n",
    "        message (str): the string to be tokenised.\n",
    "    Returns:\n",
    "        words (str): returns a string of only relevant words\n",
    "    \"\"\"\n",
    "        # replace the html characters with \" \"\n",
    "    text=re.sub('<.*?>', ' ', text)\n",
    "#     Removal of numbers\n",
    "#    text = re.sub(r'\\d+', ' ', text)\n",
    "    # will replace newline with space\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    # will convert to lower case\n",
    "    text = text.lower()\n",
    "    # will split and join the words\n",
    "    text=' '.join(text.split())\n",
    "   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "40ff1f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text= train_df.text.apply(messages_processing)\n",
    "test_df.text= test_df.text.apply(messages_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48829d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0e91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d026226f",
   "metadata": {},
   "source": [
    "#### Obvervations\n",
    "##### Visual Assessment\n",
    "1. The train contains the text and language id, while the test contains only text\n",
    "2. All text appear to be in lower case\n",
    "3. there still appeaers to be a bit of hyphens in the some texts\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "b2e4b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "import pickle\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "2344b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1, 10), analyzer='char').fit(train_df['text'])\n",
    "X_counts= vect.transform(train_df['text'])\n",
    "pred_x= vect.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "36162e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans= TfidfTransformer(norm='l1', sublinear_tf=True)\n",
    "X_tran= trans.fit_transform(X_counts)\n",
    "pred_x= trans.fit_transform(pred_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "9c58df02",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 230. MiB for an array with shape (60164551,) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [436]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # create targets and features dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# X_counts= vect.fit_transform(train_df['text'])\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# X_trans= trans.fit_transform(X_counts)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Normalizing the X_train\u001b[39;00m\n\u001b[0;32m      8\u001b[0m norm\u001b[38;5;241m=\u001b[39m MaxAbsScaler()\n\u001b[1;32m----> 9\u001b[0m X\u001b[38;5;241m=\u001b[39m \u001b[43mnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tran\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1150\u001b[0m, in \u001b[0;36mMaxAbsScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1183\u001b[0m, in \u001b[0;36mMaxAbsScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1174\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1175\u001b[0m     X,\n\u001b[0;32m   1176\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_pass,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1180\u001b[0m )\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m-> 1183\u001b[0m     mins, maxs \u001b[38;5;241m=\u001b[39m \u001b[43mmin_max_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m     max_abs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(np\u001b[38;5;241m.\u001b[39mabs(mins), np\u001b[38;5;241m.\u001b[39mabs(maxs))\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\sparsefuncs.py:509\u001b[0m, in \u001b[0;36mmin_max_axis\u001b[1;34m(X, axis, ignore_nan)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (sp\u001b[38;5;241m.\u001b[39mcsr_matrix, sp\u001b[38;5;241m.\u001b[39mcsc_matrix)):\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ignore_nan:\n\u001b[1;32m--> 509\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sparse_nan_min_max\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    511\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _sparse_min_max(X, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\sparsefuncs.py:477\u001b[0m, in \u001b[0;36m_sparse_nan_min_max\u001b[1;34m(X, axis)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sparse_nan_min_max\u001b[39m(X, axis):\n\u001b[1;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43m_sparse_min_or_max\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m)\u001b[49m, _sparse_min_or_max(X, axis, np\u001b[38;5;241m.\u001b[39mfmax))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\sparsefuncs.py:464\u001b[0m, in \u001b[0;36m_sparse_min_or_max\u001b[1;34m(X, axis, min_or_max)\u001b[0m\n\u001b[0;32m    462\u001b[0m     axis \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_min_or_max_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_or_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid axis, use 0 for rows, or 1 for columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\sparsefuncs.py:430\u001b[0m, in \u001b[0;36m_min_or_max_axis\u001b[1;34m(X, axis, min_or_max)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-size array to reduction operation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    429\u001b[0m M \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m axis]\n\u001b[1;32m--> 430\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtocsc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[0;32m    431\u001b[0m mat\u001b[38;5;241m.\u001b[39msum_duplicates()\n\u001b[0;32m    432\u001b[0m major_index, value \u001b[38;5;241m=\u001b[39m _minor_reduce(mat, min_or_max)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py:184\u001b[0m, in \u001b[0;36mcsr_matrix.tocsc\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[0;32m    180\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39mupcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    182\u001b[0m csr_tocsc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    183\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(idx_dtype),\n\u001b[1;32m--> 184\u001b[0m           \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    185\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    186\u001b[0m           indptr,\n\u001b[0;32m    187\u001b[0m           indices,\n\u001b[0;32m    188\u001b[0m           data)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csc_matrix\n\u001b[0;32m    191\u001b[0m A \u001b[38;5;241m=\u001b[39m csc_matrix((data, indices, indptr), shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 230. MiB for an array with shape (60164551,) and data type int32"
     ]
    }
   ],
   "source": [
    "# # create targets and features dataset\n",
    "# X_counts= vect.fit_transform(train_df['text'])\n",
    "# X_trans= trans.fit_transform(X_counts)\n",
    "# y= train_df['lang_id']\n",
    "# X= vect.transform(X_pre_vect)\n",
    "\n",
    "# Normalizing the X_train\n",
    "norm= MaxAbsScaler()\n",
    "X= norm.fit_transform(X_tran)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd394878",
   "metadata": {},
   "source": [
    "(33000, 4229883)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab49968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ddd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one or more ML models\n",
    "model = MultinomialNB(alpha=1, fit_prior=True, )\n",
    "model.fit(X,y)\n",
    "\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070efac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)\n",
    "logreg_acc= accuracy_score(y_pred, y_test)\n",
    "print(f\"Test accuracy: {round(logreg_acc, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "778c0930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred= model.predict(pred_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "24fee8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b= [i for i in range(1, len(a)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "8ab3d2a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       583\n",
      "         eng       1.00      1.00      1.00       615\n",
      "         nbl       1.00      1.00      1.00       583\n",
      "         nso       1.00      1.00      1.00       625\n",
      "         sot       1.00      1.00      1.00       618\n",
      "         ssw       1.00      1.00      1.00       584\n",
      "         tsn       1.00      1.00      1.00       598\n",
      "         tso       1.00      1.00      1.00       561\n",
      "         ven       1.00      1.00      1.00       634\n",
      "         xho       1.00      1.00      1.00       609\n",
      "         zul       1.00      1.00      1.00       590\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_class_report(clf, X_test, y_test):\n",
    "    #your code here\n",
    "    y_pred= clf.predict(X_test)\n",
    "    report= classification_report(y_test, y_pred)\n",
    "    return report\n",
    "\n",
    "print(get_class_report(model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "d75fdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df= pd.DataFrame({'index': b, 'lang_id': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f4f145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "4686f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('mnb9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af9da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss chosen methods "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
