{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Classification Hackathon\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "#libraries for...\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "import pickle\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('resources/train_set.csv')\n",
    "test_df= pd.read_csv('resources/test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [],
   "source": [
    "# to get a visaual assessment of different sampled observations in the train dataset\n",
    "train_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e961c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get a visaual assessment of different sampled observations in the test dataset\n",
    "test_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Futher look at the some smapled contents of contents of the text each dataset\n",
    "# Train Data\n",
    "for i in train_df['text'].sample(10):\n",
    "    print(i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a744dbd",
   "metadata": {},
   "source": [
    "#### Obvervations\n",
    "##### Visual Assessment\n",
    "1. The train contains the text and language id, while the test contains only text\n",
    "2. All text appear to be in lower case\n",
    "3. there still appeaers to be a bit of hyphens in the some texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372856b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_processing(text):\n",
    "    \"\"\"\n",
    "    Returns a sringof words, tokeninses and removes noise in the string\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): the string to be tokenised.\n",
    "    Returns:\n",
    "        text (str): returns a string of words with no punctuations\n",
    "    \"\"\"\n",
    "    text=re.sub('<.*?>', '', text)\n",
    "    text = re.sub(\"\\n\",\"\",text)\n",
    "    text = text.lower()\n",
    "    text=' '.join(text.split())\n",
    "   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b907167",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text= train_df.text.apply(messages_processing)\n",
    "test_df.text= test_df.text.apply(messages_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d38a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create features\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1, 10), analyzer='char').fit(train_df['text'])\n",
    "X_counts= vect.transform(train_df['text'])\n",
    "pred_x= vect.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ce617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To scale both test and train features\n",
    "\n",
    "trans= TfidfVectorizer(norm='l1', sublinear_tf=True).fit(train_df['text'])\n",
    "X_tran= trans.transform(X_counts)\n",
    "pred_x= trans.transform(pred_x)\n",
    "norm= MaxAbsScaler(copy=False)\n",
    "X= norm.fit_transform(X_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e6228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one or more ML models\n",
    "model = MultinomialNB(alpha=1, fit_prior=True, )\n",
    "model.fit(X_test,y_test)\n",
    "\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "y_pred= model.predict(X_test)\n",
    "logreg_acc= accuracy_score(y_pred, y_test)\n",
    "print(f\"Test accuracy: {logreg_acc}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d92ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "\n",
    "def get_class_report(clf, X_test, y_test):\n",
    "    #your code here\n",
    "    y_pred= clf.predict(X_test)\n",
    "    report= classification_report(y_test, y_pred)\n",
    "    return report\n",
    "\n",
    "print(get_class_report(model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec10f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test\n",
    "\n",
    "y_pred= model.predict(pred_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abed459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "\n",
    "a=len(y_pred)\n",
    "b= [i for i in range(1, a+1)]\n",
    "sub_df= pd.DataFrame({'index': b, 'lang_id': y_pred})\n",
    "sub_df.to_csv('mnb2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d835f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4784f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
